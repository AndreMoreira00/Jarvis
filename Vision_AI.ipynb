{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "import google\n",
    "import pathlib\n",
    "\n",
    "import edge_tts\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import time\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import math\n",
    "\n",
    "import  pyaudio\n",
    "import wave\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jarvis ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY  = os.getenv(\"API_GEMINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Voc√™ √© um assistente e eu sou o seu mestre. Voc√™ √© designado a me ajudar para solucionar qualquer quest√£o l√≥gica que eu fizer. Sempre me trate e se refira a mim como \"Mestre\". N√£o use na sua resposta caracteres especiais como (***): {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICES = ['pt-BR-AntonioNeural']\n",
    "VOICE = VOICES[0]\n",
    "OUTPUT_FILE = 'text_speech.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Voice(translate) -> None:\n",
    "    communicate = edge_tts.Communicate(translate, VOICE)\n",
    "    await communicate.save(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_cahche_files():\n",
    "    print(\"My files:\")\n",
    "    for f in genai.list_files():\n",
    "        print(\"  \", f.name)\n",
    "        \n",
    "        myfile = genai.get_file(f.name)\n",
    "        myfile.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def text_to_text(prompt) -> None:\n",
    "  response = model.generate_content(prompt)\n",
    "  if __name__ == \"__main__\":\n",
    "    await Voice(response.text)\n",
    "    os.system('text_speech.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def image_to_text(image_path, prompt) -> None:\n",
    "  response = model.generate_content([{'mime_type':'image/jpeg', 'data': pathlib.Path(f'{image_path}').read_bytes()}, prompt])\n",
    "  await Voice(response.text)\n",
    "  os.system('text_speech.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def video_to_text(video_file_name, prompt) -> None:\n",
    "  \n",
    "  video_file = genai.upload_file(path=video_file_name)\n",
    "  \n",
    "  while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "  if video_file.state.name == \"FAILED\":\n",
    "    raise ValueError(video_file.state.name)\n",
    "\n",
    "  print(\"Making LLM inference request...\")\n",
    "  response = model.generate_content([video_file, prompt],\n",
    "                                    request_options={\"timeout\": 600})\n",
    "\n",
    "  await Voice(response.text)\n",
    "  os.system('text_speech.mp3')\n",
    "  \n",
    "  delete_cahche_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_foto(frame):\n",
    "    timesr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    cv2.imwrite(f\"Images/{timesr}.jpg\", frame)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    return f\"Images/{timesr}.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Gravar Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video():\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    timesr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    duration_in_seconds = 15\n",
    "    fps = 30\n",
    "    \n",
    "    out = cv2.VideoWriter(f'Video/{timesr}.avi', fourcc, fps, (640, 480))\n",
    "    \n",
    "    total_frames = duration_in_seconds * fps\n",
    "\n",
    "    frame_count = 0\n",
    "    while frame_count < total_frames:\n",
    "        \n",
    "        status, frame = cap.read()\n",
    "        out.write(frame)\n",
    "        frame_count+=1\n",
    "        \n",
    "    return f'Video/{timesr}.avi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Mic() -> None:\n",
    "  microfone = sr.Recognizer()\n",
    "  print(\"Diga alguma coisa: \")\n",
    "  with sr.Microphone() as source:\n",
    "    audio = microfone.listen(source)\n",
    "  try:\n",
    "    frase = microfone.recognize_google(audio, language=\"pt-BR\")\n",
    "    print(frase)\n",
    "    return await text_to_text(frase)\n",
    "  except sr.UnknownValueError:\n",
    "    print(\"N√£o entendi\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Audio():\n",
    "  audio = pyaudio.PyAudio()\n",
    "  \n",
    "  stream = audio.open(\n",
    "    input = True,\n",
    "    format = pyaudio.paInt16,\n",
    "    channels = 1,\n",
    "    rate = 44000,\n",
    "    frames_per_buffer = 1024,\n",
    "  )\n",
    "  \n",
    "  frames = []\n",
    "  \n",
    "  timeout = 15\n",
    "  timeout_start = time.time()\n",
    "  \n",
    "  try:\n",
    "    while time.time() < timeout_start + timeout:\n",
    "      bloco = stream.read(1024)\n",
    "      frames.append(bloco)\n",
    "  except KeyboardInterrupt:\n",
    "      pass\n",
    "  \n",
    "  arquivo_final = wave.open(\"audio/gravacao.wav\", \"wb\")\n",
    "  arquivo_final.setnchannels(1)\n",
    "  arquivo_final.setframerate(44000)\n",
    "  arquivo_final.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "  arquivo_final.writeframes(b\"\".join(frames))\n",
    "  arquivo_final.close()\n",
    "  \n",
    "  r = sr.Recognizer()\n",
    "\n",
    "  with sr.WavFile(\"audio/gravacao.wav\") as source:              \n",
    "    audio = r.record(source)                        \n",
    "\n",
    "  try:\n",
    "      return (\"\"+r.recognize_google(audio, language=\"pt-BR\"))\n",
    "  except LookupError:         \n",
    "      return(\"Sem Falas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Imagem / Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Image_Audio(frame) -> None:  \n",
    "  with ThreadPoolExecutor() as executor:\n",
    "    future_foto = executor.submit(save_foto, frame)\n",
    "    future_audio = executor.submit(Audio)\n",
    "\n",
    "    path_foto = future_foto.result()\n",
    "    prompt = future_audio.result()                       \n",
    "\n",
    "  await image_to_text(path_foto,prompt)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Video / Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Video_Audio() -> None: \n",
    "  with ThreadPoolExecutor() as executor:\n",
    "    future_video = executor.submit(save_video)\n",
    "    future_audio = executor.submit(Audio)\n",
    "\n",
    "    path_video = future_video.result()\n",
    "    prompt = future_audio.result()\n",
    "  \n",
    "    await video_to_text(path_video, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_distancia(ponto1, ponto2):\n",
    "    \"\"\"Calcula a dist√¢ncia euclidiana entre dois pontos.\"\"\"\n",
    "    return math.sqrt((ponto1[0] - ponto2[0])**2 + (ponto1[1] - ponto2[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### üëå (Foto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok(h, w, hand_landmarks, frame):\n",
    "    \n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    \n",
    "    polegar_3 = hand_landmarks.landmark[3]\n",
    "    polegar_3_x, polegar_3_y = int(polegar_3.x * w), int(polegar_3.y * h)\n",
    "    \n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    \n",
    "    indicador_6 = hand_landmarks.landmark[6]\n",
    "    indicador_6_x, indicador_6_y = int(indicador_6.x * w), int(indicador_6.y * h)\n",
    "    \n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_y = int(medio_12.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_y = int(anelar_16.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_y = int(mindinho_20.y * h)\n",
    "    \n",
    "    distancia_polegar_indicador = calcular_distancia(\n",
    "        (polegar_4_x, polegar_4_y),\n",
    "        (indicador_8_x, indicador_8_y)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (distancia_polegar_indicador < 0.05 * w and \n",
    "        indicador_5_y > indicador_6_y and\n",
    "        polegar_1_y > indicador_6_y and  \n",
    "        polegar_3_x > indicador_5_x):  \n",
    "            return save_foto(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### üëç (Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(h, w, hand_landmarks, frame):\n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    \n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "    medio_9 = hand_landmarks.landmark[9]\n",
    "    medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "    anelar_13 = hand_landmarks.landmark[13]\n",
    "    anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "    mindinho_17 = hand_landmarks.landmark[17]\n",
    "    mindinho_17_x, mindinho_17_y = int(mindinho_17.x * w), int(mindinho_17.y * h)\n",
    "    \n",
    "    \n",
    "    if (polegar_4_y < polegar_1_y - 0.05 * h and  \n",
    "        indicador_8_y > indicador_5_y and         \n",
    "        medio_12_y > medio_9_y and               \n",
    "        anelar_16_y > anelar_13_y and            \n",
    "        mindinho_20_y > mindinho_17_y):          \n",
    "        return save_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ‚òùÔ∏è (Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(h, w, hand_landmarks, frame):\n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    \n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "    medio_9 = hand_landmarks.landmark[9]\n",
    "    medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "    anelar_13 = hand_landmarks.landmark[13]\n",
    "    anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "    mindinho_17 = hand_landmarks.landmark[17]\n",
    "    mindinho_17_x, mindinho_17_y = int(mindinho_17.x * w), int(mindinho_17.y * h)\n",
    "    \n",
    "    palma_0 = hand_landmarks.landmark[0]\n",
    "    palma_y = int(palma_0.y * h)\n",
    "    \n",
    "    if (indicador_8_y < indicador_5_y - 0.05 * h and \n",
    "        polegar_4_x > polegar_1_x and                 \n",
    "        medio_12_y > medio_9_y and                   \n",
    "        anelar_16_y > anelar_13_y and                \n",
    "        mindinho_20_y > mindinho_17_y):              \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### üëÜ (Foto e Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(h, w, hand_landmarks, frame):\n",
    "  \n",
    "  indicador_8 = hand_landmarks.landmark[8]\n",
    "  indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "  indicador_6 = hand_landmarks.landmark[6]\n",
    "  indicador_6_x, indicador_6_y = int(indicador_6.x * w), int(indicador_6.y * h)\n",
    "  \n",
    "  polegar_4 = hand_landmarks.landmark[4]\n",
    "  polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "  polegar_2 = hand_landmarks.landmark[2]\n",
    "  polegar_2_x, polegar_2_y = int(polegar_2.x * w), int(polegar_2.y * h)\n",
    "  \n",
    "  medio_12 = hand_landmarks.landmark[12]\n",
    "  medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "  medio_9 = hand_landmarks.landmark[9]\n",
    "  medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "  \n",
    "  anelar_16 = hand_landmarks.landmark[16]\n",
    "  anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "  anelar_13 = hand_landmarks.landmark[13]\n",
    "  anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "  \n",
    "  mindinho_20 = hand_landmarks.landmark[20]\n",
    "  mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "  mindinho_17 = hand_landmarks.landmark[17]\n",
    "  mindinho_17_x, mindinho_17_y = int(mindinho_17.x * w), int(mindinho_17.y * h)\n",
    "  \n",
    "  if (indicador_8_y < indicador_6_y - 0.05 * h and\n",
    "        polegar_4_x < polegar_2_x and\n",
    "        mindinho_20_y > mindinho_17_y and                  \n",
    "        medio_12_y > medio_9_y and                   \n",
    "        anelar_16_y > anelar_13_y): \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ü§ü (Video e Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rock(h, w, hand_landmarks, frame):\n",
    "  \n",
    "  indicador_8 = hand_landmarks.landmark[8]\n",
    "  indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "  indicador_6 = hand_landmarks.landmark[6]\n",
    "  indicador_6_x, indicador_6_y = int(indicador_6.x * w), int(indicador_6.y * h)\n",
    "  \n",
    "  mindinho_20 = hand_landmarks.landmark[20]\n",
    "  mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "  mindinho_18 = hand_landmarks.landmark[18]\n",
    "  mindinho_18_x, mindinho_18_y = int(mindinho_18.x * w), int(mindinho_18.y * h)\n",
    "  \n",
    "  medio_12 = hand_landmarks.landmark[12]\n",
    "  medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "  medio_9 = hand_landmarks.landmark[9]\n",
    "  medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "  \n",
    "  anelar_16 = hand_landmarks.landmark[16]\n",
    "  anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "  anelar_13 = hand_landmarks.landmark[13]\n",
    "  anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "  \n",
    "  if (indicador_8_y < indicador_6_y - 0.05 * h and\n",
    "        mindinho_20_y < mindinho_18_y - 0.05 * h and                  \n",
    "        medio_12_y > medio_9_y and                   \n",
    "        anelar_16_y > anelar_13_y): \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o frame.\")\n",
    "        break\n",
    "    \n",
    "    # Espelhar a camera (Desativado)\n",
    "    # frame = cv2.flip(frame, 1)    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "      \n",
    "      for hand_landmarks, hand_handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "        \n",
    "        hand_label = hand_handedness.classification[0].label\n",
    "        \n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Inverte as m√£os Left/Right\n",
    "        # Programa:\n",
    "        \n",
    "        if hand_label == \"Right\" and ok(h, w, hand_landmarks, frame):\n",
    "          time.sleep(0.5)\n",
    "        \n",
    "        if hand_label == \"Left\" and positive(h, w, hand_landmarks, frame):\n",
    "          time.sleep(0.5)\n",
    "        \n",
    "        if hand_label == \"Right\" and speak(h, w, hand_landmarks, frame):\n",
    "          await Mic()\n",
    "          time.sleep(0.5)\n",
    "        \n",
    "        if hand_label == \"Left\" and L(h, w, hand_landmarks, frame):\n",
    "          await Image_Audio(frame)\n",
    "          time.sleep(0.5)\n",
    "        \n",
    "        if hand_label == \"Right\" and rock(h, w, hand_landmarks, frame):\n",
    "          await Video_Audio()\n",
    "          time.sleep(0.5)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    cv2.imshow(\"MediaPipe Hands - Gestos Especificos\", frame) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
