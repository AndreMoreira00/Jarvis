{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import edge_tts\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import time\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import math\n",
    "\n",
    "import  pyaudio\n",
    "import wave\n",
    "\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jarvis ü§ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"API_GROQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Voc√™ √© um assistente e eu sou o seu mestre. Voc√™ √© designado a me ajudar para solucionar qualquer quest√£o l√≥gica que eu fizer. Sempre me trate e se refira a mim como \"Mestre\": {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template=template)\n",
    "chat = ChatGroq(api_key=key , model='llama-3.1-8b-instant')\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICES = ['pt-BR-AntonioNeural']\n",
    "VOICE = VOICES[0]\n",
    "OUTPUT_FILE = 'text_speech.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Voice(translate) -> None:\n",
    "    communicate = edge_tts.Communicate(translate, VOICE)\n",
    "    await communicate.save(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Jarvis(text) -> None:\n",
    "  translate = f\"{chain.invoke(text).content}\"\n",
    "  if __name__ == \"__main__\":\n",
    "    # loop = asyncio.get_event_loop()\n",
    "    # try:\n",
    "      # loop.run_until_complete(await Voice(translate))\n",
    "    await Voice(translate)\n",
    "    print(\"Audio Salvo!\")\n",
    "    os.system('text_speech.mp3')\n",
    "    # finally:\n",
    "    #   loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_foto(frame):\n",
    "    timesr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    cv2.imwrite(f\"Images/{timesr}.jpg\", frame)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Gravar Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video():\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    timesr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    duration_in_seconds = 15\n",
    "    fps = 30\n",
    "    \n",
    "    out = cv2.VideoWriter(f'Video/{timesr}.avi', fourcc, fps, (640, 480))\n",
    "    \n",
    "    total_frames = duration_in_seconds * fps\n",
    "\n",
    "    frame_count = 0\n",
    "    while frame_count < total_frames:\n",
    "        \n",
    "        status, frame = cap.read()\n",
    "        out.write(frame)\n",
    "        frame_count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Mic() -> None:\n",
    "  microfone = sr.Recognizer()\n",
    "  print(\"Diga alguma coisa: \")\n",
    "  with sr.Microphone() as source:\n",
    "    audio = microfone.listen(source)\n",
    "  try:\n",
    "    frase = microfone.recognize_google(audio, language=\"pt-BR\")\n",
    "    print(frase)\n",
    "    return await Jarvis(frase)\n",
    "  except sr.UnknownValueError:\n",
    "    print(\"N√£o entendi\")\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Video / Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video_Audio():  \n",
    "  audio = pyaudio.PyAudio()\n",
    "  \n",
    "  stream = audio.open(\n",
    "    input = True,\n",
    "    format = pyaudio.paInt16,\n",
    "    channels = 1,\n",
    "    rate = 44000,\n",
    "    frames_per_buffer = 1024,\n",
    "  )\n",
    "  \n",
    "  frames = []\n",
    "  \n",
    "  timeout = 15\n",
    "  timeout_start = time.time()\n",
    "  \n",
    "  try:\n",
    "    while time.time() < timeout_start + timeout:\n",
    "      bloco = stream.read(1024)\n",
    "      frames.append(bloco)\n",
    "  except KeyboardInterrupt:\n",
    "      pass\n",
    "  \n",
    "  arquivo_final = wave.open(\"audio/gravacao.wav\", \"wb\")\n",
    "  arquivo_final.setnchannels(1)\n",
    "  arquivo_final.setframerate(44000)\n",
    "  arquivo_final.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "  arquivo_final.writeframes(b\"\".join(frames))\n",
    "  arquivo_final.close()\n",
    "  \n",
    "  r = sr.Recognizer()\n",
    "\n",
    "  with sr.WavFile(\"audio/gravacao.wav\") as source:              \n",
    "    audio = r.record(source)                        \n",
    "\n",
    "  try:\n",
    "      print(\"\" + r.recognize_google(audio, language=\"pt-BR\"))   \n",
    "  except LookupError:         \n",
    "      print(\"Sem Falas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_distancia(ponto1, ponto2):\n",
    "    \"\"\"Calcula a dist√¢ncia euclidiana entre dois pontos.\"\"\"\n",
    "    return math.sqrt((ponto1[0] - ponto2[0])**2 + (ponto1[1] - ponto2[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### üëå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok(h, w, hand_landmarks, frame):\n",
    "    \n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    \n",
    "    polegar_3 = hand_landmarks.landmark[3]\n",
    "    polegar_3_x, polegar_3_y = int(polegar_3.x * w), int(polegar_3.y * h)\n",
    "    \n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    \n",
    "    indicador_6 = hand_landmarks.landmark[6]\n",
    "    indicador_6_x, indicador_6_y = int(indicador_6.x * w), int(indicador_6.y * h)\n",
    "    \n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_y = int(medio_12.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_y = int(anelar_16.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_y = int(mindinho_20.y * h)\n",
    "    \n",
    "    distancia_polegar_indicador = calcular_distancia(\n",
    "        (polegar_4_x, polegar_4_y),\n",
    "        (indicador_8_x, indicador_8_y)\n",
    "    )\n",
    "\n",
    "    if (distancia_polegar_indicador < 0.05 * w and \n",
    "\n",
    "        (indicador_5_y - indicador_6_y) > 0.02 * h and  \n",
    "        (polegar_1_y - indicador_6_y) > 0.02 * h and  \n",
    "        (polegar_3_x - indicador_5_x) > 0.02 * w):  \n",
    "            return save_foto(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### üëç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(h, w, hand_landmarks, frame):\n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    \n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "    medio_9 = hand_landmarks.landmark[9]\n",
    "    medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "    anelar_13 = hand_landmarks.landmark[13]\n",
    "    anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "    mindinho_17 = hand_landmarks.landmark[17]\n",
    "    mindinho_17_x, mindinho_17_y = int(mindinho_17.x * w), int(mindinho_17.y * h)\n",
    "    \n",
    "    \n",
    "    if (polegar_4_y < polegar_1_y - 0.05 * h and  \n",
    "        indicador_8_y > indicador_5_y and         \n",
    "        medio_12_y > medio_9_y and               \n",
    "        anelar_16_y > anelar_13_y and            \n",
    "        mindinho_20_y > mindinho_17_y):          \n",
    "        return save_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ‚òùÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(h, w, hand_landmarks, frame):\n",
    "    indicador_8 = hand_landmarks.landmark[8]\n",
    "    indicador_8_x, indicador_8_y = int(indicador_8.x * w), int(indicador_8.y * h)\n",
    "    \n",
    "    indicador_5 = hand_landmarks.landmark[5]\n",
    "    indicador_5_x, indicador_5_y = int(indicador_5.x * w), int(indicador_5.y * h)\n",
    "    \n",
    "    polegar_4 = hand_landmarks.landmark[4]\n",
    "    polegar_4_x, polegar_4_y = int(polegar_4.x * w), int(polegar_4.y * h)\n",
    "    polegar_1 = hand_landmarks.landmark[1]\n",
    "    polegar_1_x, polegar_1_y = int(polegar_1.x * w), int(polegar_1.y * h)\n",
    "    \n",
    "    medio_12 = hand_landmarks.landmark[12]\n",
    "    medio_12_x, medio_12_y = int(medio_12.x * w), int(medio_12.y * h)\n",
    "    medio_9 = hand_landmarks.landmark[9]\n",
    "    medio_9_x, medio_9_y = int(medio_9.x * w), int(medio_9.y * h)\n",
    "    \n",
    "    anelar_16 = hand_landmarks.landmark[16]\n",
    "    anelar_16_x, anelar_16_y = int(anelar_16.x * w), int(anelar_16.y * h)\n",
    "    anelar_13 = hand_landmarks.landmark[13]\n",
    "    anelar_13_x, anelar_13_y = int(anelar_13.x * w), int(anelar_13.y * h)\n",
    "    \n",
    "    mindinho_20 = hand_landmarks.landmark[20]\n",
    "    mindinho_20_x, mindinho_20_y = int(mindinho_20.x * w), int(mindinho_20.y * h)\n",
    "    mindinho_17 = hand_landmarks.landmark[17]\n",
    "    mindinho_17_x, mindinho_17_y = int(mindinho_17.x * w), int(mindinho_17.y * h)\n",
    "    \n",
    "    palma_0 = hand_landmarks.landmark[0]\n",
    "    palma_y = int(palma_0.y * h)\n",
    "    \n",
    "    if (indicador_8_y < indicador_5_y - 0.05 * h and \n",
    "        polegar_4_x > polegar_1_x and                 \n",
    "        medio_12_y > medio_9_y and                   \n",
    "        anelar_16_y > anelar_13_y and                \n",
    "        mindinho_20_y > mindinho_17_y):              \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### ü§ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rock(h, w, hand_landmarks, frame):\n",
    "  return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o frame.\")\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "      \n",
    "      for hand_landmarks, hand_handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "        \n",
    "        hand_label = hand_handedness.classification[0].label\n",
    "        \n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Programa:\n",
    "        if hand_label == \"Left\" and ok(h, w, hand_landmarks, frame):\n",
    "          time.sleep(0.5)\n",
    "        if hand_label == \"Right\" and positive(h, w, hand_landmarks, frame):\n",
    "          time.sleep(0.5)\n",
    "        if hand_label == \"Left\" and speak(h, w, hand_landmarks, frame):\n",
    "          await Mic()\n",
    "          time.sleep(0.5)\n",
    "        if hand_label == \"Right\" and rock(h, w, hand_landmarks, frame):\n",
    "          t1 = Thread(target=Video_Audio)\n",
    "          t2 = Thread(target=save_video)\n",
    "          t1.start()\n",
    "          t2.start()\n",
    "          time.sleep(0.5)\n",
    "        # //\n",
    "        \n",
    "        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    cv2.imshow(\"MediaPipe Hands - Gestos Especificos\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
